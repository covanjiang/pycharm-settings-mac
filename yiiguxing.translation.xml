<application>
  <component name="AppStorage">
    <option name="newTranslationDialogX" value="786" />
    <option name="newTranslationDialogY" value="484" />
    <histories>
      <item value="Content" />
      <item value="supplementary" />
      <item value="compensation" />
      <item value="discrepancies" />
      <item value="There are discrepancies in media consumption, please check your email!" />
      <item value="Media consumption indistinguishable data!" />
      <item value="preamble" />
      <item value="transpose" />
      <item value="embedding" />
      <item value="When the timeout argument is not present or None, the operation will block until the thread terminates. A thread can be join()ed many times. join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception." />
      <item value="hen the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call isAlive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out." />
      <item value="This blocks the calling thread until the thread whose join() method is called terminates -- either normally or through an unhandled exception or until the optional timeout occurs." />
      <item value="statements" />
      <item value="Normally, THttpServer always sends a 200 response. If a handler wants to override this behavior (e.g., to simulate a misconfigured or overloaded web server during testing), it can raise a ResponseException. The function passed to the constructor will be called with the RequestHandler as its only argument. Note that this is irrelevant for ONEWAY requests, as the HTTP response must be sent before the RPC is processed." />
      <item value="propagate" />
      <item value="income" />
      <item value="Domestic" />
      <item value="stats latency" />
      <item value="latency" />
      <item value="accuracy" />
      <item value="A toolset for quality control, evlation and processing of GRID-seq libarary." />
      <item value="known case of datetime.datetime.utcnow &quot;&quot;&quot; Return a new datetime representing UTC day and time." />
      <item value="Unexpected argument&#10;" />
      <item value="Unexpected argument" />
      <item value="The delimiter according which to split the string. None (the default value) means split according to any whitespace, and discard empty strings from the result. maxsplit&#10;" />
      <item value="The delimiter according which to split the string. None (the default value) means split according to any whitespace, and discard empty strings from the result. maxsplit" />
      <item value="Returns the approximate memory footprint an object and all of its contents. Automatically finds the contents of the following builtin containers and their subclasses: tuple, list, deque, dict, set and frozenset. To search other containers, add handlers to iterate over their contents: handlers = {SomeContainerClass: iter, OtherContainerClass: OtherContainerClass.get_elements}" />
      <item value="verbose" />
      <item value="so slow" />
      <item value="Get polyA peaks for given set of depths" />
      <item value="fusion reads" />
      <item value="sorted ids of intervals in cluster(tuples)" />
      <item value="Cluster reads into positive strand and negative strand" />
      <item value="minimal reads to support APAspeaks" />
      <item value="minimal distance between two adjacent APAspeaks" />
      <item value="Shadows name 'split_unit' from outer scope" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="32" />
        <entry key="ENGLISH" value="33" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1657510488418" />
  </component>
  <component name="Translation.Cache">
    <option name="lastTrimTime" value="1688960021929" />
  </component>
  <component name="Translation.States">
    <option name="newTranslationDialogX" value="912" />
    <option name="newTranslationDialogY" value="452" />
    <option name="pinTranslationDialog" value="true" />
    <histories>
      <item value="Chain that combines documents by stuffing into context. This chain takes a list of documents and first combines them into a single string. It does this by formatting each document into a string with the `document_prompt` and then joining them together with `document_separator`. It then adds that new string to the inputs with the variable name set by `document_variable_name`. Those inputs are then passed to the `llm_chain`." />
      <item value="Chain to use to combine the documents." />
      <item value="Optional metadata associated with the chain. Defaults to None This metadata will be associated with each call to this chain, and passed as arguments to the handlers defined in `callbacks`. You can use these to eg identify a specific instance of a chain with its use case." />
      <item value="Optional list of tags associated with the chain. Defaults to None These tags will be associated with each call to this chain, and passed as arguments to the handlers defined in `callbacks`. You can use these to eg identify a specific instance of a chain with its use case." />
      <item value="Whether or not run in verbose mode. In verbose mode, some intermediate logs will be printed to the console. Defaults to `langchain.verbose` value." />
      <item value="Optional list of callback handlers (or callback manager). Defaults to None. Callback handlers are called throughout the lifecycle of a call to a chain, starting with on_chain_start, ending with on_chain_end or on_chain_error. Each custom chain can optionally call additional callback methods, see Callback docs for full details." />
      <item value="Optional memory object. Defaults to None. Memory is a class that gets called at the start and at the end of every chain. At the start, memory loads variables and passes them along in the chain. At the end, it saves any returned variables. There are many different types of memory - please see memory docs for the full catalog." />
      <item value="Abstract base class for creating structured sequences of calls to components. Chains should be used to encode a sequence of calls to components like models, document retrievers, other chains, etc., and provide a simple interface to this sequence. The Chain interface makes it easy to create apps that are: - Stateful: add Memory to any Chain to give it state, - Observable: pass Callbacks to a Chain to execute additional functionality, like logging, outside the main sequence of component calls, - Composable: the Chain API is flexible enough that it is easy to combine Chains with other components, including other Chains. The main methods exposed by chains are: - `__call__`: Chains are callable. The `__call__` method is the primary way to execute a Chain. This takes inputs as a dictionary and returns a dictionary output. - `run`: A convenience method that takes inputs as argskwargs and returns the output as a string. This method can only be used for a subset of chains and cannot return as rich of an output as `__call__`." />
      <item value="Calculate num tokens for gpt-3.5-turbo and gpt-4 with tiktoken package. Official documentation: https:github.comopenaiopenai-cookbookblob mainexamplesHow_to_format_inputs_to_ChatGPT_models.ipynb" />
      <item value="Number of chat completions to generate for each prompt.&quot;" />
      <item value="Pass a sequence of prompts to the model and return model generations. This method should make use of batched calls for models that expose a batched API. Use this method when you want to: 1. take advantage of batched calls, 2. need more output from the model than just the top generated value, 3. are building chains that are agnostic to the underlying language model type (e.g., pure text completion models vs chat models). Args: prompts: List of PromptValues. A PromptValue is an object that can be converted to match the format of any language model (string for pure text generation models and BaseMessages for chat models). stop: Stop words to use when generating. Model output is cut off at the first occurrence of any of these substrings. callbacks: Callbacks to pass through. Used for executing additional functionality, such as logging or streaming, throughout generation. kwargs: Arbitrary additional keyword arguments. These are usually passed to the model provider API call. Returns: An LLMResult, which contains a list of candidate Generations for each input prompt and additional model provider-specific output." />
      <item value="We hope to increase the number of inputs per request soon" />
      <item value="It is possible to do more validation of the headers, but a request could always be made to the API manually with invalid headers, so we need to handle them server side." />
      <item value="Wait 2^x 1 second between each retry starting with 4 seconds, then up to 10 seconds, then 10 seconds afterwards" />
      <item value="Encodes a string into tokens. Special tokens are artificial tokens used to unlock capabilities from a model, such as fill-in-the-middle. So we want to be careful about accidentally encoding special tokens, since they can be used to trick a model into doing something we don't want it to do. Hence, by default, encode will raise an error if it encounters text that corresponds to a special token. This can be controlled on a per-token level using the `allowed_special` and `disallowed_special` parameters. In particular: - Setting `disallowed_special` to () will prevent this function from raising errors and cause all text corresponding to special tokens to be encoded as natural text. - Setting `allowed_special` to &quot;all&quot; will cause this function to treat all text corresponding to special tokens to be encoded as special tokens." />
      <item value="Check if the model matches a known prefix Prefix matching avoids needing library updates for every model version release Note that this can match on non-existent models (e.g., gpt-3.5-turbo-FAKE)" />
      <item value="The model name to pass to tiktoken when using this class. Tiktoken is used to count the number of tokens in documents to constrain them to be under a certain limit. By default, when set to None, this will be the same as the embedding model name. However, there are some cases where you may want to use this Embedding class with a model name not supported by tiktoken. This can include when using Azure embeddings or when using one of the many model providers that expose an OpenAI-like API but with different models. In those cases, in order to avoid erroring when tiktoken is called, you can specify a model name to use here." />
      <item value="&quot;3. When referencing the context to answer a question, &quot; &quot;if there are image references in the context, &quot; &quot;first divide the context into several sections based on these images. &quot; &quot;Then, respond to the question according to each section, &quot; &quot;and use the corresponding image references to &quot; &quot;connect the answers together to form a complete response to the question. \n&quot;" />
      <item value="&quot;3. When referencing the context to answer questions, &quot; &quot;if there are image references within the context, &quot; &quot;first split the context into sections according to these image references. &quot; &quot;Then, answer the questions based on each section. &quot; &quot;Finally, connect your answers using the corresponding image references &quot; &quot;to provide a holistic response to the question. \n&quot;" />
      <item value="and use the corresponding image references to &quot; &quot;connect the answers together to form a complete response to the question." />
      <item value="Then, respond to the question according to each section," />
      <item value="first divide the context into several sections based on these images." />
      <item value="Finally, connect your answers using the corresponding image references" />
      <item value="Then, answer the questions based on each section." />
      <item value="first split the context into sections according to these image references." />
      <item value="It's crucial to place the image reference accurately in your response. The image reference must be inserted right after the sentence or paragraph that describes or refers to the content of the image." />
      <item value="Every time you respond to a user's question, you should ask yourself whether there are image references related to the context you are referencing in your response. If there are, include these image references at the correct position in your response to enhance its accuracy and reliability." />
      <item value="Each time you respond to a user's question, always ask yourself: Is there a related image reference in the context? If there is, you must include the corresponding image reference in your response, and the image reference should directly follow its related content." />
      <item value="Adhere to the following rules when handling these references" />
      <item value="which are used to further elucidate the context they immediately follow" />
      <item value="These references, used to elaborate on the text immediately preceding them" />
      <item value="In the context, images are denoted using the format ![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-3245653demo}, where 'img_v2_6ecf4367-a6ab-4b11-bfc5-3245653demo' is a unique identifier for an image. These references, used to elaborate on the text immediately preceding them, should be handled as follows:" />
      <item value="Also, overlook the image references within these specific instructions, implying not to include '![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-3245659ddemo}' in your responses. Nevertheless, if the section of context your answer refers to contains image data, it's mandatory to include it, ensuring a logical correlation with the respective text." />
      <item value="Remember not to fabricate these image identifiers or the encapsulating format '![image]{...}'." />
      <item value="It is crucial to recognize and handle these references appropriately, ensuring their inclusion in your responses where relevant, and accurately relating them to the preceding text." />
      <item value="It is crucial to recognize and handle these references appropriately, &quot; &quot;ensuring their inclusion in your responses where relevant, &quot; &quot;and accurately relating them to the preceding text." />
      <item value="If the section of context your answer refers to contains image data, &quot; &quot;it's mandatory to include it, ensuring a logical correlation with the respective text." />
      <item value="Remember not to fabricate these image identifiers &quot; &quot;or the encapsulating format '![image]{...}'." />
      <item value="implying not to include '![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-3245653demo}' &quot; &quot;in your responses." />
      <item value="implying not to include '![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-3245653demo}'" />
      <item value="overlook the image references within these specific instructions" />
      <item value="overlook" />
      <item value="mandatory" />
      <item value="overlook the image references within these specific instructions," />
      <item value="It is crucial to recognize and handle these references appropriately, ensuring their inclusion in your responses where relevant, and accurately relating them to the preceding text. Remember not to fabricate these image identifiers or the encapsulating format '![image]{...}'. Also, overlook the image references within these specific instructions, implying not to include '![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-3245659ddemo}' in your responses. Nevertheless, if the section of context your answer refers to contains image data, it's mandatory to include it, ensuring a logical correlation with the respective text." />
      <item value="If the provided context is insufficient to support your answer to this question, your response should be '哎呀，这个问题好像有点超出了我的知识范围。您可以直接联系臧迪解决，后续会完善更新知识库哦。'." />
      <item value="As 'XiaoMeng' ('小萌'), your mandate is to answer questions relying exclusively on the provided context, with a strict prohibition on using any prior knowledge. If the context is insufficient, your response should be '哎呀，这个问题好像有点超出了我的知识范围。您可以直接联系臧迪解决，后续会完善更新知识库哦。'. Ensure to replicate verbatim any hyperlinks encountered within the segment of context referenced in your response for enhanced detail and accuracy. When returning a hyperlink in your response, ensure to provide the plain URL directly, without applying any additional formatting or enclosing it in brackets or parentheses. The expected output should be the direct URL itself, allowing it to be clickable and directly accessible by the user. Make certain your response's language aligns with that of the user's question (The default language is Chinese). Provide your responses straightaway, without any added explanation or phrases like 'according to the provided context' or '根据提供的上下文'. Take note that in the context, images are represented in the format ![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-32456593demo}. Here, 'img_v2_6ecf4367-a6ab-4b11-bfc5-32456593demo' is a unique identifier for a particular image. These image references are included to further explain the text that directly precedes them. It is crucial to recognize and handle these references appropriately, ensuring their inclusion in your responses where relevant, and accurately relating them to the preceding text. Remember not to fabricate these image identifiers or the encapsulating format '![image]{...}'." />
      <item value="Nevertheless, if the section of context your answer refers to contains image data, it's mandatory to include it, ensuring a logical correlation with the respective text." />
      <item value="Also, overlook the image references within these specific instructions, implying not to include '![image]{img_v2_6ecf4367-a6ab-4b11-bfc5-3245659ddemo}' in your responses." />
      <item value="These image references are included to further explain the text that directly precedes them." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="296" />
        <entry key="ENGLISH" value="299" />
      </map>
    </option>
  </component>
</application>