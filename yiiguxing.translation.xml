<application>
  <component name="AppStorage">
    <option name="newTranslationDialogX" value="786" />
    <option name="newTranslationDialogY" value="484" />
    <histories>
      <item value="Content" />
      <item value="supplementary" />
      <item value="compensation" />
      <item value="discrepancies" />
      <item value="There are discrepancies in media consumption, please check your email!" />
      <item value="Media consumption indistinguishable data!" />
      <item value="preamble" />
      <item value="transpose" />
      <item value="embedding" />
      <item value="When the timeout argument is not present or None, the operation will block until the thread terminates. A thread can be join()ed many times. join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception." />
      <item value="hen the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). As join() always returns None, you must call isAlive() after join() to decide whether a timeout happened -- if the thread is still alive, the join() call timed out." />
      <item value="This blocks the calling thread until the thread whose join() method is called terminates -- either normally or through an unhandled exception or until the optional timeout occurs." />
      <item value="statements" />
      <item value="Normally, THttpServer always sends a 200 response. If a handler wants to override this behavior (e.g., to simulate a misconfigured or overloaded web server during testing), it can raise a ResponseException. The function passed to the constructor will be called with the RequestHandler as its only argument. Note that this is irrelevant for ONEWAY requests, as the HTTP response must be sent before the RPC is processed." />
      <item value="propagate" />
      <item value="income" />
      <item value="Domestic" />
      <item value="stats latency" />
      <item value="latency" />
      <item value="accuracy" />
      <item value="A toolset for quality control, evlation and processing of GRID-seq libarary." />
      <item value="known case of datetime.datetime.utcnow &quot;&quot;&quot; Return a new datetime representing UTC day and time." />
      <item value="Unexpected argument&#10;" />
      <item value="Unexpected argument" />
      <item value="The delimiter according which to split the string. None (the default value) means split according to any whitespace, and discard empty strings from the result. maxsplit&#10;" />
      <item value="The delimiter according which to split the string. None (the default value) means split according to any whitespace, and discard empty strings from the result. maxsplit" />
      <item value="Returns the approximate memory footprint an object and all of its contents. Automatically finds the contents of the following builtin containers and their subclasses: tuple, list, deque, dict, set and frozenset. To search other containers, add handlers to iterate over their contents: handlers = {SomeContainerClass: iter, OtherContainerClass: OtherContainerClass.get_elements}" />
      <item value="verbose" />
      <item value="so slow" />
      <item value="Get polyA peaks for given set of depths" />
      <item value="fusion reads" />
      <item value="sorted ids of intervals in cluster(tuples)" />
      <item value="Cluster reads into positive strand and negative strand" />
      <item value="minimal reads to support APAspeaks" />
      <item value="minimal distance between two adjacent APAspeaks" />
      <item value="Shadows name 'split_unit' from outer scope" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="32" />
        <entry key="ENGLISH" value="33" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1657510488418" />
  </component>
  <component name="Translation.Cache">
    <option name="lastTrimTime" value="1688960021929" />
  </component>
  <component name="Translation.States">
    <option name="newTranslationDialogX" value="912" />
    <option name="newTranslationDialogY" value="452" />
    <option name="pinTranslationDialog" value="true" />
    <histories>
      <item value="Disregard the images mentioned in this tips." />
      <item value="Deliver your responses directly without any additional explanation &quot; &quot;or the use of phrases like 'according to the provided context'." />
      <item value="Refrain from fabricating image references that are not present in the context." />
      <item value="If so, incorporate the corresponding image reference in your response, &quot; &quot;positioned immediately after its related text." />
      <item value="Remember, the corresponding image information should be tightly coupled with the related text in your answer." />
      <item value="not present in the context." />
      <item value="Refrain from fabricating image references that are not specified within the context." />
      <item value="However, refrain from fabricating image information if it's not present in the context." />
      <item value="Refrain from inventing image references that are not specified within the context." />
      <item value="If so, incorporate the corresponding image reference in your response, positioned immediately after its related text." />
      <item value="If so, and the image is relevant to your response, you must incorporate the image information." />
      <item value="always consider" />
      <item value="consistently ask yourself" />
      <item value="As XiaoMeng, you must adhere strictly to the rules specified in the prompts" />
      <item value="representing a specific image. When your response involves the relevant images" />
      <item value="adorably intelligent" />
      <item value="The context may include several pieces of text as well as images represented as ![image]{img_v2_744f616d-0464-494b-8eaf-b18f5e07a66g}." />
      <item value="The context may include several pieces of text as well as images &quot; &quot;represented as ![image]{img_v2_744f616d-0464-494b-8eaf-b18f5e07a66g}." />
      <item value="You are provided with several pieces of context text &quot; &quot;which might also include images represented as ![image]{random_key}." />
      <item value="represented" />
      <item value="cutting-edge intelligent" />
      <item value="Optional list of callback handlers (or callback manager). Defaults to None. Callback handlers are called throughout the lifecycle of a call to a chain, starting with on_chain_start, ending with on_chain_end or on_chain_error. Each custom chain can optionally call additional callback methods, see Callback docs for full details." />
      <item value="Run the logic of this chain and add to output if desired. Args: inputs: Dictionary of inputs, or single input if chain expects only one param. return_only_outputs: boolean for whether to return only outputs in the response. If True, only new keys generated by this chain will be returned. If False, both input keys and new keys generated by this chain will be returned. Defaults to False. callbacks: Callbacks to use for this chain run. If not provided, will use the callbacks provided to the chain. tags: Optional list of tags associated with the chain. Defaults to None metadata: Optional metadata associated with the chain. Defaults to None include_run_info: Whether to include run info in the response. Defaults to False." />
      <item value="Wrapper around Azure OpenAI Chat Completion API. To use this class you must have a deployed model on Azure OpenAI. Use `deployment_name` in the constructor to refer to the &quot;Model deployment name&quot; in the Azure portal." />
      <item value="The model name to pass to tiktoken when using this class. Tiktoken is used to count the number of tokens in documents to constrain them to be under a certain limit. By default, when set to None, this will be the same as the embedding model name. However, there are some cases where you may want to use this Embedding class with a model name not supported by tiktoken. This can include when using Azure embeddings or when using one of the many model providers that expose an OpenAI-like API but with different models. In those cases, in order to avoid erroring when tiktoken is called, you can specify a model name to use here." />
      <item value="Penalizes repeated tokens according to frequency." />
      <item value="Total probability mass of tokens to consider at each step." />
      <item value="The maximum number of tokens to generate in the completion. -1 returns as many tokens as possible given the prompt and the models maximal context size." />
      <item value="Pears are either red or orange" />
      <item value="it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv" />
      <item value="How to determine the score: - Higher is a better answer - Better responds fully to the asked question, with sufficient level of detail - If you do not know the answer based on the context, that should be a score of 0 - Don't be overconfident!" />
      <item value="In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:" />
      <item value="If ``ensure_ascii`` is false, then the return value can contain non-ASCII characters if they appear in strings contained in ``obj``. Otherwise, all such characters are escaped in JSON strings." />
      <item value="This is a temporary workaround to make the similarity search asynchronous. The proper solution is to make the similarity search asynchronous in the vector store implementations." />
      <item value="&quot;&quot;&quot;Run the logic of this chain and add to output if desired. Args: inputs: Dictionary of inputs, or single input if chain expects only one param. return_only_outputs: boolean for whether to return only outputs in the response. If True, only new keys generated by this chain will be returned. If False, both input keys and new keys generated by this chain will be returned. Defaults to False. callbacks: Callbacks to use for this chain run. If not provided, will use the callbacks provided to the chain. include_run_info: Whether to include run info in the response. Defaults to False. &quot;&quot;&quot;" />
      <item value="close: if left at its default of ``True``, has the effect of fully closing all currently checked in database connections. Connections that are still checked out will not be closed, however they will no longer be associated with this :class:`_engine.Engine`, so when they are closed individually, eventually the :class:`_pool.Pool` which they are associated with will be garbage collected and they will be closed out fully, if not already closed on checkin." />
      <item value="Split each pair by one or more newline characters possibly surrounded by whitespaces" />
      <item value="Split the content by two or more newline characters possibly surrounded by whitespaces" />
      <item value="Returns an active Redis client generated from the given database URL. Will attempt to extract the database id from the path url fragment, if none is provided." />
      <item value="You might need to adjust how you initialize your database, feishu client, and vector database, based on how FastAPI handles asynchronous operations." />
      <item value="PEP 8: E741 ambiguous variable name 'l'" />
      <item value="Batch size to use when passing multiple documents to generate." />
      <item value="Holds any model parameters valid for `create` call not explicitly specified." />
      <item value="Generates best_of completions server-side and returns the &quot;best&quot;." />
      <item value="How many completions to generate for each prompt." />
      <item value="Penalizes repeated tokens." />
      <item value="Given the context information and not prior knowledge, answer the question" />
      <item value="&quot;&quot;&quot;Wrapper around Azure-specific OpenAI large language models. To use, you should have the ``openai`` python package installed, and the environment variable ``OPENAI_API_KEY`` set with your API key. Any parameters that are valid to be passed to the openai.create call can be passed in, even if not explicitly saved on this class. Example: .. code-block:: python from langchain.llms import AzureOpenAI openai = AzureOpenAI(model_name=&quot;text-davinci-003&quot;) &quot;&quot;&quot;" />
      <item value="Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer." />
      <item value="Call predict on the LLM." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="211" />
        <entry key="ENGLISH" value="213" />
      </map>
    </option>
  </component>
</application>